{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTkZOyKrJ8gs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "!pip install aiohttp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qE-wv1dItSaK",
        "outputId": "e371e74d-f0b6-483f-ede3-3de735c2cc99"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://www.transfermarkt.com/nathan-ake/leistungsdatendetails/spieler/177476/saison//verein/0/liga/0/wettbewerb//pos/0/trainer_id/0/plus/1'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all = pd.read_parquet('allPlayersDetailsLink.parquet',engine='pyarrow')\n",
        "linkesUnique=all['playersLink'].tolist()\n",
        "listlink=[]\n",
        "for i in range(len(linkesUnique)):\n",
        "  listlink.append('https://www.transfermarkt.com'+linkesUnique[i])\n",
        "uncatched = []\n",
        "listlink[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeLO6mOssOkD"
      },
      "outputs": [],
      "source": [
        "for i in range(0,9400,100):\n",
        "  start = time.time()\n",
        "  import asyncio\n",
        "  import aiohttp\n",
        "  import time\n",
        "  import nest_asyncio\n",
        "  nest_asyncio.apply()\n",
        "  # uncatched=[]\n",
        "  playersId ,birthDate,birthPlace,citizenship,height,position,currentValue,timeValue,season,competition,age =[],[],[],[],[],[],[],[],[],[],[]\n",
        "  competitionUnicName,club,clubId,squad,appearances,ppg,goals,assists,ownGoal,subsituationsOn=[],[],[],[],[],[],[],[],[],[]\n",
        "  subsituationsOff,yellowCards,secondYellowCards,redCards,penalyGoals,minutesPerGoal,minutesPlayed,goalsConceded,cleanSheets=[],[],[],[],[],[],[],[],[]\n",
        "  headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'}\n",
        "  columns = ['playersId','birthDate','birthPlace','citizenship','height','position','currentValue','timeValue','season','competition','age'\\\n",
        "            ,'competitionUnicName','club','clubId','squad','appearances','ppg','goals','assists','ownGoal','subsituationsOn'\\\n",
        "            ,'subsituationsOff','yellowCards','secondYellowCards','redCards','penalyGoals','minutesPerGoal','minutesPlayed','goalsConceded','cleanSheets']\n",
        "  data = [playersId ,birthDate,birthPlace,citizenship,height,position,currentValue,timeValue,season,competition,age,\\\n",
        "            competitionUnicName,club,clubId,squad,appearances,ppg,goals,assists,ownGoal,subsituationsOn\\\n",
        "            ,subsituationsOff,yellowCards,secondYellowCards,redCards,penalyGoals,minutesPerGoal,minutesPlayed,goalsConceded,cleanSheets]\n",
        "  async def get(url, session):\n",
        "      try:\n",
        "          async with session.get(url=url) as response:\n",
        "              resp = await response.read()\n",
        "              pageSoup = BeautifulSoup(resp , 'html.parser')\n",
        "              head = pageSoup.find_all('div',{'class':'data-header__details'})[0].find_all('ul')[0]\n",
        "              head2 = pageSoup.find_all('div',{'class':'data-header__details'})[0].find_all('ul')[1]\n",
        "              \n",
        "              # print(url)\n",
        "              size = len(pageSoup.find_all('table',{'class':'items'})[0].find_all('th'))\n",
        "              for i in range(len(pageSoup.find_all('table',{'class':'items'})[0].tbody.find_all('tr'))):\n",
        "                head3 = pageSoup.find_all('table',{'class':'items'})[0].tbody.find_all('tr')[i]\n",
        "                if(size ==18): #not goal keeper\n",
        "                  try:\n",
        "                    playersId.append(url.split('/spieler/')[1].split('/')[0])\n",
        "                  except:\n",
        "                    playersId.append(np.nan)\n",
        "                  try:\n",
        "                    birthDate.append(head.li.span.text.strip().split('(')[0].strip())\n",
        "                  except:\n",
        "                    birthDate.append(np.nan)\n",
        "                  try:\n",
        "                    age.append(head.li.span.text.strip().split('(')[1].strip(')'))\n",
        "                  except:\n",
        "                    age.append(np.nan)\n",
        "                  try:\n",
        "                    birthPlace.append(head.find_all('li')[1].span.text.strip())\n",
        "                  except:\n",
        "                    birthPlace.append(np.nan)\n",
        "                  try:\n",
        "                    citizenship.append(head.find_all('li')[2].span.text.strip())\n",
        "                  except: \n",
        "                    citizenship.append(np.nan)\n",
        "                  try: \n",
        "                    height.append(head2.find_all('li')[0].span.text.strip())\n",
        "                  except:\n",
        "                    height.append(np.nan)\n",
        "                  try:\n",
        "                    position.append(head2.find_all('li')[1].span.text.strip())\n",
        "                  except:\n",
        "                    position.append(np.nan)\n",
        "              # pageSoup.find_all('div',{'class':'data-header__details'})[0].find_all('ul')[1].find_all('li')[2].span.text.strip()\n",
        "                  try:\n",
        "                    currentValue.append(pageSoup.find_all('div',{'class':'data-header__box--small'})[0].text.split('Last update')[0].strip())\n",
        "                  except:\n",
        "                    currentValue.append(np.nan)\n",
        "                  try:\n",
        "                    timeValue.append(pageSoup.find_all('div',{'class':'data-header__box--small'})[0].text.split('Last update')[1].strip(':\\n'))\n",
        "                  except:\n",
        "                    timeValue.append(np.nan)\n",
        "                  try:\n",
        "                    season.append(head3.find_all('td')[0].text)\n",
        "                  except:\n",
        "                    season.append(np.nan)\n",
        "                  try:\n",
        "                    competition.append(head3.find_all('td')[1].img.get('title'))\n",
        "                  except:\n",
        "                    competition.append(np.nan)\n",
        "                  try:\n",
        "                    competitionUnicName.append(head3.find_all('td')[2].a.get('href').split('/saison_id')[0].split('/')[-1])\n",
        "                  except:\n",
        "                    competition.append(np.nan)\n",
        "\n",
        "                  \n",
        "                  try:\n",
        "                    club.append(head3.find_all('td')[3].img.get('alt'))\n",
        "                  except:\n",
        "                    club.append(np.nan)\n",
        "                  try:\n",
        "                    clubId.append(head3.find_all('td')[3].a.get('href').split('verein/')[1].split('/')[0])\n",
        "                  except:\n",
        "                    clubId.append(np.nan)\n",
        "                  try:\n",
        "\n",
        "                    squad.append(head3.find_all('td')[4].text)\n",
        "                  except:\n",
        "                    squad.append(np.nan)\n",
        "                  try:  \n",
        "                    appearances.append(head3.find_all('td')[5].text)\n",
        "                  except:\n",
        "                    appearances.append(np.nan)\n",
        "                  try:\n",
        "              \n",
        "                    ppg.append(head3.find_all('td')[6].text)\n",
        "                  except:\n",
        "                    ppg.append(np.nan)\n",
        "                  try:\n",
        "\n",
        "                    goals.append(head3.find_all('td')[7].text)\n",
        "                  except:\n",
        "                    goals.append(np.nan)\n",
        "                  try:\n",
        "                    assists.append(head3.find_all('td')[8].text)\n",
        "                  except:\n",
        "                    assists.append(np.nan)\n",
        "                  try:\n",
        "                    ownGoal.append(head3.find_all('td')[9].text)\n",
        "                  except:\n",
        "                    ownGoal.apppend(np.nan)\n",
        "                  try:  \n",
        "                    subsituationsOn.append(head3.find_all('td')[10].text)\n",
        "                  except:\n",
        "                    subsituationsOn.append(np.nan)\n",
        "                  try:  \n",
        "                    subsituationsOff.append(head3.find_all('td')[11].text)\n",
        "                  except:\n",
        "                    subsituationsOff.append(np.nan)\n",
        "                  try:  \n",
        "                    yellowCards.append(head3.find_all('td')[12].text)\n",
        "                  except:\n",
        "                    yellowCards.append(np.nan)\n",
        "                  try:  \n",
        "                    secondYellowCards.append(head3.find_all('td')[13].text)\n",
        "                  except:\n",
        "                    secondYellowCards.append(np.nan)\n",
        "                  try:  \n",
        "                    redCards.append(head3.find_all('td')[14].text)\n",
        "                  except:\n",
        "                    redCards.append(np.nan)  \n",
        "                  try:  \n",
        "                    penalyGoals.append(head3.find_all('td')[15].text)\n",
        "                  except:\n",
        "                    penalyGoals.append(np.nan)\n",
        "                  try:  \n",
        "                    minutesPerGoal.append(head3.find_all('td')[16].text)\n",
        "                  except:\n",
        "                    minutesPerGoal.append(np.nan)\n",
        "                  try:  \n",
        "                      minutesPlayed.append(head3.find_all('td')[17].text)\n",
        "                  except:\n",
        "                    minutesPlayed.append(np.nan)\n",
        "                  \n",
        "                  goalsConceded.append('not a goalKeeper')\n",
        "                  cleanSheets.append('not a goalKeeper')\n",
        "                else:\n",
        "                  try:\n",
        "                    playersId.append(url.split('/spieler/')[1].split('/')[0])\n",
        "                  except:\n",
        "                    playersId.append(np.nan)\n",
        "                  try:\n",
        "                    birthDate.append(head.li.span.text.strip().split('(')[0].strip())\n",
        "                  except:\n",
        "                    birthDate.append(np.nan)\n",
        "                  try:\n",
        "                    age.append(head.li.span.text.strip().split('(')[1].strip(')'))\n",
        "                  except:\n",
        "                    age.append(np.nan)\n",
        "                  try:\n",
        "                    birthPlace.append(head.find_all('li')[1].span.text.strip())\n",
        "                  except:\n",
        "                    birthPlace.append(np.nan)\n",
        "                  try:\n",
        "                    citizenship.append(head.find_all('li')[2].span.text.strip())\n",
        "                  except: \n",
        "                    citizenship.append(np.nan)\n",
        "                  try: \n",
        "                    height.append(head2.find_all('li')[0].span.text.strip())\n",
        "                  except:\n",
        "                    height.append(np.nan)\n",
        "                  try:\n",
        "                    position.append(head2.find_all('li')[1].span.text.strip())\n",
        "                  except:\n",
        "                    position.append(np.nan)\n",
        "              # pageSoup.find_all('div',{'class':'data-header__details'})[0].find_all('ul')[1].find_all('li')[2].span.text.strip()\n",
        "                  try:\n",
        "                    currentValue.append(pageSoup.find_all('div',{'class':'data-header__box--small'})[0].text.split('Last update')[0].strip())\n",
        "                  except:\n",
        "                    currentValue.append(np.nan)\n",
        "                  try:\n",
        "                    timeValue.append(pageSoup.find_all('div',{'class':'data-header__box--small'})[0].text.split('Last update')[1].strip(':\\n'))\n",
        "                  except:\n",
        "                    timeValue.append(np.nan)\n",
        "                  try:\n",
        "                    season.append(head3.find_all('td')[0].text)\n",
        "                  except:\n",
        "                    season.append(np.nan)\n",
        "                  try:\n",
        "                    competition.append(head3.find_all('td')[1].img.get('title'))\n",
        "                  except:\n",
        "                    competition.append(np.nan)\n",
        "                  try:\n",
        "                    competitionUnicName.append(head3.find_all('td')[2].a.get('href').split('/saison_id')[0].split('/')[-1])\n",
        "                  except:\n",
        "                    competition.append(np.nan)\n",
        "\n",
        "                  \n",
        "                  try:\n",
        "                    club.append(head3.find_all('td')[3].img.get('alt'))\n",
        "                  except:\n",
        "                    club.append(np.nan)\n",
        "                  try:\n",
        "                    clubId.append(head3.find_all('td')[3].a.get('href').split('verein/')[1].split('/')[0])\n",
        "                  except:\n",
        "                    clubId.append(np.nan)\n",
        "                  try:\n",
        "\n",
        "                    squad.append(head3.find_all('td')[4].text)\n",
        "                  except:\n",
        "                    squad.append(np.nan)\n",
        "                  try:  \n",
        "                    appearances.append(head3.find_all('td')[5].text)\n",
        "                  except:\n",
        "                    appearances.append(np.nan)\n",
        "                  try:\n",
        "              \n",
        "                    ppg.append(head3.find_all('td')[6].text)\n",
        "                  except:\n",
        "                    ppg.append(np.nan)\n",
        "                  try:\n",
        "\n",
        "                    goals.append(head3.find_all('td')[7].text)\n",
        "                  except:\n",
        "                    goals.append(np.nan)\n",
        "                  assists.append('goalKeeper')\n",
        "                  try:\n",
        "                    ownGoal.append(head3.find_all('td')[8].text)\n",
        "                  except:\n",
        "                    ownGoal.append(np.nan)\n",
        "                  try:\n",
        "                    subsituationsOn.append(head3.find_all('td')[9].text)\n",
        "                  except:\n",
        "                    subsituationsOn.append(np.nan)\n",
        "                  try:\n",
        "                    subsituationsOff.append(head3.find_all('td')[10].text)\n",
        "                  except:\n",
        "                    subsituationsOff.append(np.nan)\n",
        "                  try:\n",
        "                    yellowCards.append(head3.find_all('td')[11].text)\n",
        "                  except:\n",
        "                    yellowCards.append(np.nan)\n",
        "                  try:\n",
        "                    secondYellowCards.append(head3.find_all('td')[12].text)\n",
        "                  except:\n",
        "                    secondYellowCards.append(np.nan)\n",
        "\n",
        "                  try:\n",
        "                    redCards.append(head3.find_all('td')[13].text)\n",
        "                  except:\n",
        "                    redCards.append(head3.find_all('td')[13].text)\n",
        "                  penalyGoals.append('goalKeeper')\n",
        "                  try:\n",
        "                    cleanSheets.append(head3.find_all('td')[14].text)\n",
        "                  except:\n",
        "                    cleanSheets.append(np.nan)\n",
        "\n",
        "                  minutesPerGoal.append('goalKeeper')\n",
        "                  try:\n",
        "                    goalsConceded.append(head3.find_all('td')[15].text)\n",
        "                  except:\n",
        "                    goalsConceded.append(np.nan)\n",
        "                  try:\n",
        "                    minutesPlayed.append(head3.find_all('td')[16].text)\n",
        "                  except:\n",
        "                    minutesPlayed.append(np.nan)    \n",
        "            \n",
        "      except Exception as e:\n",
        "          print(\"Unable to get url {} due to {}.\".format(url, e.__class__))\n",
        "          uncatched.append(url)\n",
        "  connector = aiohttp.TCPConnector(limit=100)\n",
        "      \n",
        "\n",
        "  async def main(urls):\n",
        "      async with aiohttp.ClientSession(connector=connector) as session:\n",
        "          ret = await asyncio.gather(*[get(url, session) for url in urls])\n",
        "      # df = pd.DataFrame({'playersId':playersId,'season':season_ , 'date':date_ , 'left':left_ , 'joined':joined_ , 'mv':mv_ , 'fee':fee_})\n",
        "      # print(\"Finalized all. Return is a list of len {} outputs.\".format(len(ret)))\n",
        "      print(len(uncatched))\n",
        "\n",
        "  \n",
        "  urls = listlink[i:i+100]\n",
        "  asyncio.run(main(urls))\n",
        "  if(i==0):\n",
        "    df1= pd.DataFrame({columns[0]:data[0],columns[1]:data[1],columns[2]:data[2],columns[3]:data[3],columns[4]:data[4],columns[5]:data[5],columns[6]:data[6],columns[7]:data[7],\\\n",
        "              columns[8]:data[8],columns[9]:data[9],columns[10]:data[10],columns[11]:data[11],columns[12]:data[12],columns[13]:data[13],columns[14]:data[14],\\\n",
        "              columns[15]:data[15],columns[16]:data[16],columns[17]:data[17],columns[18]:data[18],columns[19]:data[19],columns[20]:data[20],columns[21]:data[21],\\\n",
        "              columns[22]:data[22],columns[23]:data[23],columns[24]:data[24],columns[25]:data[25],columns[26]:data[26],columns[27]:data[27],columns[28]:data[28],\\\n",
        "              columns[29]:data[29]})\n",
        "  else:\n",
        "    df= pd.DataFrame({columns[0]:data[0],columns[1]:data[1],columns[2]:data[2],columns[3]:data[3],columns[4]:data[4],columns[5]:data[5],columns[6]:data[6],columns[7]:data[7],\\\n",
        "              columns[8]:data[8],columns[9]:data[9],columns[10]:data[10],columns[11]:data[11],columns[12]:data[12],columns[13]:data[13],columns[14]:data[14],\\\n",
        "              columns[15]:data[15],columns[16]:data[16],columns[17]:data[17],columns[18]:data[18],columns[19]:data[19],columns[20]:data[20],columns[21]:data[21],\\\n",
        "              columns[22]:data[22],columns[23]:data[23],columns[24]:data[24],columns[25]:data[25],columns[26]:data[26],columns[27]:data[27],columns[28]:data[28],\\\n",
        "              columns[29]:data[29]})\n",
        "    df1=pd.concat([df1,df],axis=0)\n",
        "\n",
        "\n",
        "  \n",
        "end = time.time()\n",
        "\n",
        "print(\"Took {} seconds to pull {} websites.\".format(end - start, len(urls)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsHjhMPC-eRM"
      },
      "outputs": [],
      "source": [
        "df1.reset_index(drop=True).to_parquet('allPlayersFeature (1).parquet',engine='pyarrow')\n",
        "# df1.reset_index(drop=True).to_csv('allPlayersFeature.csv')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
